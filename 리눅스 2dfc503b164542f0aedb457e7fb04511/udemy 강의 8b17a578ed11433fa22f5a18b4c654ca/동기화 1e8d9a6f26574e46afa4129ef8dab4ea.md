# 동기화

SMP : OS 복사본이 각각의 cpu에 있음

- cpu bottleneck 감소(master cpu가 없으니깐)
- 여러 cpu가 동시에 동일한 프로세스 혹은 메모리 페이지 할당하게 된다면 문제가 생김 ⇒ 뮤텍스로 해결

선점 : 현재 프로세스 선점, 타이머 인터럽트 isr 실행

context switching : 스레드간의 프로세서의 상태 변경시 발생(레지스터, 모드 ,스택 …)

스케쥴러 : 타이머 인터럽트 후에 호출.

유저 영역은 항상 선점..

커널 영역 선점하는 경우

- 인터럽트 핸들러에서 커널 공간으로 리턴
- 커널 코드가 재선점
- schedule() 호출
- 커널 태스크 차단(schedule()호출 발생)

동시성 원인

- 인터럽트
- softirqs / tasklets
- 커널 선점
- sleeping / 사용자 공간 동기화
- smp

동시성 해결

- 하드웨어 인터럽트 비활성화 : 짧은 시간동안만 사용해야함
- 커널 선점 비활성화 : smp에서는 제대로 안됨(글로별 변수 동시에 엑세스 가능해서)

smp_processor_id()

#include <linux/percpu.h>

cpu별로 변수 따로 설정하는게 가능한데 쓸일 있나?

이렇게 해도 인터럽트하고 비동기함수(지연된 함수같은거…) 못막음

 Atomic

- read - modify - write 어셈블리 언어 명령어일 경우 한 어셈블리 명령어에 처리되는게 아니고 여러번 사용해야하니 여러 CPU에서 동일한 위치 읽고 변경하려고 하면 문제가 생김

![Untitled](%E1%84%83%E1%85%A9%E1%86%BC%E1%84%80%E1%85%B5%E1%84%92%E1%85%AA%201e8d9a6f26574e46afa4129ef8dab4ea/Untitled.png)

그래서 pthread 2개 만들어서 i++를 10000000해주는 스레드 돌리면 glob = 943003 이렇게 나옴(문제가 있음!)

- 단일 명령만으로 수행 가능해야함
- atomic_t  원자 명령 보장한다는 뜻

<asm/atomic.h>
typedef struct { volatile int counter; } atomic_t;

```jsx
atomic_ti = ATOMIC_INIT(1); //i를 1로 초기화
void atomic_inc(atomic_t *i); //*i에 1 추가
void atomic_dec(atomic_t *i); //*i에서 1 빼기
void atomic_set(atomic_t *i, int j); //원자적으로 역i를 j에 지정된 값으로 설정합니다
int atomic_read(atomic_t *i); //atomic 카운터 i의 값 읽기void atomic_add(int val, atomic_t *i); //Atomically add val to atomic counter i
void atomic_add(int val, atomic_t *i); //Atomically add val to atomic counter i
void atomic_sub(int val, atomic_t *i); //Atomically subtract val from atomic counter i

int atomic_dec_and_test(atomic_t *i); //atomic Subtract 1 from *i and return 1 if the result is zero; 0 otherwise
int atomic_inc_and_test(atomic_t *i); //atomic Add 1 to *i and return 1 if the result is zero; 0 otherwise
// Atomically subtract val from *i and return 1 if the result is zero; otherwise 0
int atomic_sub_and_test(int val, atomic_t *i); 
//Atomically add val to *i and return 1 if the result is negative; otherwise 0
int atomic_add_negative(int val, atomic_t *i);

int atomic_add_return(int val, atomic_t *i);// Atomically add val to *i and return the result.
int atomic_sub_return(int val, atomic_t *i); // Atomically subtract val from *i and return the result.
int atomic_inc_return(atomic_t *i);// Atomically increment *i by one and return the result.
int atomic_dec_return(atomic_t *i);// Atomically decrement *i by one and return the result.

//Atomically set the bit nr in location starting from addr
void set_bit(int nr, volatile unsigned long *addr);
//Atomically clear the nr-th bit starting from addr.
void clear_bit(int nr, volatile unsigned long *addr);
//Atomically flip the value of the nr-th bit starting from addr.
void change_bit(int nr, volatile unsigned long *addr);

//Atomically set the bit nr in the location starting from p, and return old value at the nrth bit
int test_and_set_bit(unsigned int nr, volatile unsigned long *p);
//Atomically clear the bit nr in the location starting from p, and return old value at the nrthbit
int test_and_clear_bit(unsigned int nr, volatile unsigned long *p);
//Atomically flip the bit nr in the location starting from p, and return old value at the nrth bit
int test_and_change_bit(unsigned int nr, volatile unsigned long *p);

test_and_set_bit(0, &addr) addr이 0이 아니면 리턴값 0 값 1증가함 clear는 반대로 1감소
test_and_change_bit 이거는 n번째 비트 변경하겠다는거(flip)
```

---

## 스핀락

```c
<linux/spinlock.h>
spinlock_t
DEFINE_SPINLOCK(my_lock); == spinlock_t my_lock = __SPIN_LOCK_UNLOCKED(my_lock);
void spin_lock_init(spinlock_t *lock);

void spin_lock(spinlock_t *lock);
void spin_unlock(spinlock_t *lock);

int spin_trylock(spinlock_t *lock);
lock 못하면 0 가능하면 락걸고 0이 아닌 값 반환
```

- 재귀적이지 않아서 다른 프로세서가 깨워주길 기다려야함

그래서 spin_lock 두번 연속하면 실행이 안됨…

- 선점 비활성화됨
- 인터럽트에서는 아래 처럼 사용 (드라이버에서 lock했는데 인터럽트 걸리면 인터럽트도 lock됨..)

```jsx
unsigned long flags;

spin_lock_irqsave(&my_lock, flags);
/* critical region ... */
spin_unlock_irqrestore(&my_lock, flags);
잠그고 해제할때 인터럽트를 이전 상태로 되돌림 

인터럽트가 초기에 활성화 되어있다는 사실을 안다면 이전상태
복원할 필요없으니 아래처럼 사용

spin_lock_irq(&mr_lock);
/* critical section ... */
spin_unlock_irq(&mr_lock);

하지만 커널에서는 call depth가 깊고 인터럽트 활성화 여부 판단이 어려워서
보통 안씀
```

- 교착상태에 안빠지게 주의해야함
- 이미 lock한 후에 unlock을 해야지 다시 lock하면 교착상태에 빠짐
- 스핀락을 사용한 critical section에서는 sleep같은거 사용하면 안됨(kmalloc 같은거)
- 구현 : test and set 으로  atomic하게 처리해야함

---

## 세마포어

- sleep 가능한 lock
- lock하면 태스크를 대기열에 두고 sleep함
- 카운팅 세마포어는 상호 배제에 사용안함

```jsx
<linux/semaphore.h>
struct semaphore {
        raw_spinlock_t          lock;
        unsigned int            count; // 1이면 바이너리/ 그외 카운팅 세마포어
        struct list_head        wait_list;
};

void sema_init(struct semaphore *sem, int val);
#define DEFINE_SEMAPHORE(name)

void down(struct semaphore *sem); //p연산 take
void up(struct semaphore *sem); //v연산 give

down_interruptible() TASK_INTERRUPTIBLE로 state바꿈
take 하는 도중에 수신받으면 -EINT 리턴
즉 down(&mysem); 인데 down_interruptible(&mysem);하면
리턴값으로 -EINT 나옴

int down_trylock(struct semaphore *sem);
int down_timeout(struct semaphore *sem, long jiffies);
-ETIME

int down_killable(struct semaphore *sem);
killable하다는 거는 SIGCONT SIGCHLD SIGSTP처럼 fatal한 경우에만
kill신호처럼 전달되어 처리한다는거. interruptible이랑 동일
그니깐 ctrl + c처럼 직접 눌러야 교착상태에 안빠지고 빠져나올수 있음
```

- 짧은 시간동안만 크리티컬 섹션 처리하는데는 별로임

 sleep, wait queue, wake up같은거 때문에 오버헤드가 심함

- 인터럽트 컨텍스트에서 사용불가
- 커널 선점 활성화 되어있음(비활성화 안함)

---

## 뮤텍스

- 바이너리 세마포어 대신해서 사용하는거
- recursive lock, unlock 불가능
- 뮤텍스 holding 하는 동안에 프로세스 종료 불가
- 인터럽트 핸들러에서 뮤텍스 사용 불가

세마포어와의 차이

- 뮤텍스 흭득 경로 3가지
1. fast path : 뮤텍스 흭득한 프로세스가 없을때 실행
2. mid path : 뮤텍스 not available할때 실행

우선 순위가 높은 다른 프로세스 실행할 준비가 되어있지 않은 경우에만 실행됨

소유자가 잠금 해제하기를 바라면서 MCS 잠금하면서 회전

context switch는 비용이 크니깐 이걸 방지하는것

1. slow path : semaphore 랑 동일

```jsx
<linux/mutex.h>

struct mutex {
	atomic_long_t     owner; // 소유자, lock state
  spinlock_t        wait_lock; // wait_list 상호배제
	struct list_head  wait_list;
};

DEFINE_MUTEX(name)
mutex_init(mutex)

void mutex_lock(struct mutex *lock);
void mutex_unlock(struct mutex *lock);

int mutex_trylock(struct mutex *lock);
1 성공 0 그외

int mutex_lock_interruptible(struct mutex *lock);
0 흭득 -EINTR : 뮤텍스 기다리는 동안 시그널 받았을때

int mutex_lock_killable(struct mutex *lock);
fatal signal(SIGINT) 같은거 받으면 태스크 state를
TASK_KILLABLE 로 바꿈

int mutex_is_locked(struct mutex *lock);
1 locked 0 unlocked
```

스핀락 / 뮤텍스 사용하는 경우

- lock하는데 오버헤드가 적게 필요하다면 spinlock
- lock hold time 적다면 spinlock
- lock hold time 길다면 mutex
- 인터럽트 컨텍스트에서 사용할거면 spinlock
- sleep이 필요하다면 mutex

---

## rwlock(read write lock)

```jsx
rw 스핀락
<linux/rwlock_types.h>
struct rwlock_t
DEFINE_RWLOCK(x)
rwlock_init(lock);

Readers:
		read_lock(&mr_rwlock);
		/* critical section (read only) ... */
		read_unlock(&mr_rwlock);

Writers:
		write_lock(&mr_rwlock);
		/* critical section (read and write) ... */
		write_unlock(&mr_lock);

read_lock, write_lock 둘다 실행되면 교착상태

rw 세마포어
Header File: <linux/rwsem.h>
struct rw_semaphore
DECLARE_RWSEM(name)
init_rwsem(struct rw_semaphore *sem)

Readers:
	void down_read(struct rw_semaphore *sem);
		critical section
		....
	void up_read(struct rw_semaphore *sem);

Writers:
	void down_write(struct rw_semaphore *sem);
		critical section
		....
	void up_write(struct rw_semaphore *sem);
```

---

## sequence lock

#include <linux/seqlock.h>

---

## read copy update (RCU)

- 읽기가 많고 쓰는 경우가 드물때 사용
- 포인터 공유 자원
- reader에 lock이 없음
- sleep 불가
- 보호된 리소스는 포인터를 통해서만 엑세스
- 쓰기는 잠금이 필요
- Dentry나 routing tables에서 자주 사용함
- 공유 데이터 struct가 변경 된다면 복사본을 만들고 perform the change, 모든 reader가 이전 copy를 읽고 포인터 업데이트

```c
<linux/rcupdate.h>
rcu_read_lock()
rcu_read_unlock()
synchronize_rcu() / call_rcu()
rcu_assign_pointer()
rcu_dereference()

Write operation:
====================

	Direct assign a new pointer to a pointer is protected by RCU is forbidden

	You need to use rcu_assign_pointer() function.

	struct my_data
	{
		int key;
		int val;
	};

	struct my_data *global = NULL;

	Write operation
	----------------

	struct my_data *new_ptr;
	new_ptr = kmalloc(sizeof(struct my_data), GFP_KERNEL);
	new_ptr->key = 1;
	new_ptr->val = 1234;
	rcu_assign_pointer(global, new_ptr);

  Read operation
	----------------

	struct my_data *tmp;
	rcu_read_lock();

	tmp = rcu_dereference(global);
	pr_info("key:%d\t val:%d\n", tmp->key, tmp->val);
	rcu_read_unlock();
```

<linux/sched.h>

```c
schedule();
wake_up_process(sleeping_task);
1 woken up 0 이미 실행중
long schedule_timeout (	signed long  timeout);
0 타이머 만료 그외는 jiffies

```

```c
struct my_task_queue
{
	struct task_struct *task;
	struct list_head list_head;
};

bool write_available = false;
if(!list_empty(&head))
	{
		struct my_task_queue *sleeping_task;
		sleeping_task = list_entry(head.next, struct my_task_queue, list_head);
		list_del(head.next);
		wake_up_process(sleeping_task->task);
	}

list_add_tail(&mytask.list_head, &head);

```

task state

- TASK_INTERRUPTIBLE : sleep/block됨

시그널 보내지면 wake up 하고 runnable해짐

- TASK_UNINTERRUPTIBLE : sleep/block됨

시그널 보내져도 wake up 하지 않음. 

이건 보통 디바이스 드라이버가 디스크나 네트워크 I/O 기다린다고 주로 사용됨

```c
<linux/delay.h>
void msleep(unsigned int msecs);
unsigned long msleep_interruptible(unsigned int msecs);
void ssleep(unsigned int seconds);
```