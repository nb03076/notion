# 인터럽트

[정리](%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%90%E1%85%A5%E1%84%85%E1%85%A5%E1%86%B8%E1%84%90%E1%85%B3%20f9af428cf19f41d18915e4cfafb6ebe7/%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20e8584baaeed142a99ddac775f50bad7c.md)

```c
watch -n 1 'cat /proc/interrupts | less'

request_irq
-EBUSY면 할당 실패(이미 할당된 상태)

IRQF_SHARED면  dev_id null이면 안됨 에러발생함
IRQF NOBALANCING 특정 cpu에서만 인터럽트 작동하는듯?

$ cat /proc/irq/1/smp_affinity
00000000,00000000,00000000,00000038
This mean keyboard interrupt can occur in CPU 3, 4, 5

<linux/irqflags.h>
local_irq_disable()
local_irq_enable()

synchronize_irq() spins until no interrupt handler is running for the given IRQ
진행하고 있는 핸들러까지만 실행보장해주는 것

irq 등록 해제시에 이렇게 사용
synchronize_irq(irq);
free_irq(irq, &my_dev_id);

만약 disable_irq 두번 호출하면 enable_irq 한번만 호출했다고 활성화 되는게 아니고
두두번 호출해야지 활성화됨.
근데 disable_irq 같은 것은 irq_shared이면 모든 해당 인터럽트 다 비활성화 하니 별로안좋음
그래서 레거시 코드에서만 사용한다고 함

#include <linux/preempt.h>
in_interrupt() : 1이면 인터럽트 0이면 프로세스

hard-IRQ 핸들러(핸들러 함수) 함수가 IRQ_WAKE_THREAD를 반환하면,
이 bottop-halves과 연관된 kthread가 scheduled되어 thread_fn을 호출

소프트irq는 다른 소프트irq를 선점하지 않는다. 
소프트irq를 선점할 수 있는 유일한 이벤트는 인터럽트 핸들러입니다.
다른 소프트irq는 같은 것이라도 다른 프로세서에서 실행할 수 있다.
```

```c
<linux/gpio.h>
0:성공
int gpio_is_valid(int number);
에러처리 return -ENODEV

디바이스트리 이용안하고 gpio 컨트롤하려면?
static int  gpio_request(unsigned gpio, const char *label) 
label is the label used by the kernel for the GPIO in sysfs (/sys/kernel/debug/gpio)
Return 0 on success, negative error code on failure
EINVAL

해제
void gpio_free(unsigned int gpio)

int gpio_direction_input(unsigned gpio);
int gpio_direction_output(unsigned gpio, int value);

/* GPIO INPUT:  return zero or nonzero */
int gpio_get_value(unsigned gpio);

/* GPIO OUTPUT */
void gpio_set_value(unsigned gpio, int value);

/* kthread */
struct task_struct *blink = 
	kthread_run(led_thread, NULL, "ledthread");

static int led_thread(void* data) {
	while(!kthread_should_stop()) {

}
return 0;
}

kthread_stop(blink)

gpio_set_debounce(gpio_button, 1000);      // Debounce the button with a delay of 1000ms
irq_number = gpio_to_irq(gpio_button);

mem = (uint32_t *)ioremap(GPIO_BASE, GPIO_SIZE);
iounmap(mem);

인터럽트 핸들러 내에서는 interrupt disabled 되어있음

```

```c
IRQF_ONESHOT
hard irq 핸들러? 이거 한번만 호출하고 그뒤로 호출안함
default primary handler가 단순히 IRQ_WAKE_THREAD 해줘서
irq 스레드 깨워서 동작하게 만들어주는 역할함
hard irq 핸들러 null로 해서 동작함....

irq 스레드에서 in_interrupt하면 프로세스로 판정남
```

```c
open_softirq(이름?,핸들러)
raise_softirq(이름)
void my_action(struct softirq_action *h)

bh = bottom halves
void local_bh_disable() 	Disable softirq and tasklet processing on the local processor
void local_bh_enable()		Enable softirq and tasklet processing on the local processor

spin_lock_bh()
spin_unlock_bh()
```

```c
struct tasklet_struct
{
        struct tasklet_struct *next; /* next tasklet in the list */
        unsigned long state;   /* state of the tasklet */
        atomic_t count;		/* reference counter */
	      bool use_callback;
				union {
					void (*func)(unsigned long data);
					void (*callback)(struct tasklet_struct *t);
				};
	unsigned long data;
};

state 
a) 0
b) TASKLET_STATE_SCHED
c) TASKLET_STATE_RUN

count
count = 0 		the tasklet is enabled and can run if marked pending
count = nonzero		the tasklet is disabled and cannot run

#define DECLARE_TASKLET(name, func)
#define DECLARE_TASKLET_DISABLED(name, func)
**void tasklet_init(struct tasklet_struct *t,
                         void (*func)(unsigned long), unsigned long data);

static inline void tasklet_schedule(struct tasklet_struct *t)
TASKLET_STATE_SCHED

태스크릿에서는 sleep, blocking 함수 사용 불가
인터럽트로 작동함(in_interrupt, in_softirq둘다포함)
pid / comm은 확인가능함
irq enabled된 상태라 다른 인터럽트 발생가능

짧은 시간내에 schedule해도 pending bit에는 한번만 들어가니
여러번 실행되는게 아니고 한번만 실행됨

tasklet_disable하면 핸들러 실행중이면 실행 끝나고 나서 disable함
이렇게 안할거면 tasklet_disable_nosync사용
tasklet_kill 이거는 펜딩 큐 없애는거(인터럽트내에서는 사용x)

task_hi_schedule이게 우선순위 일반 태스크릿보다 높음

태스크릿은 동적으로 등록가능하지만 다른 프로세서에서 스케쥴은 안됨
소프트irq는 그 반대.. 컴파일 타임. / 가능**
```

```c
워크큐
work item : 실행할 함수에 대한 포인터
work queue : work item 큐 / 드라이버에서 워크아이템 추가
worker threads : 워크큐에 있는 함수 호출
worker pools : 워커 스레드 관리

workqueue 	--	struct workqueue_struct
work items	-- 	struct work_struct

struct work_struct {
        atomic_long_t data;
        struct list_head entry;
        work_func_t func;
};

#include <linux/workqueue.h>
typedef void (*work_func_t)(struct work_struct *work);
DECLARE_WORK(name, void (*function)(void *), void *data);
INIT_WORK(struct work_struct *work, void(*function)(struct work_struct *));

로컬 cpu워크큐에 enqueue하지만 실행 보장x
bool queue_work_on(int cpu, struct workqueue_struct *wq,
		struct work_struct *work)
ret : cpu번호

같은 워크 한번에 두번 enqueue하면 에러남..

queue_work_on이거 쓰면 특정 cpu에서 동작하게만듦

schedule_work - put work task in global workqueue
static inline bool schedule_work(struct work_struct *work)
{
        return queue_work(system_wq, work);
}
보면 결국 queue_work에 system_wq사용한거임

static inline bool schedule_work_on(int cpu, struct work_struct *work)

보통 work_struct는 디바이스 드라이버에 embed되어있다

인터럽트 컨텍스트는 아니지만 인터럽트 활성화 되어있는 상태임

bool cancel_work_sync(struct work_struct *work);
다음에 수행할  work item 취소함
ret:1이면 성공

bool flush_work(struct work_struct *work)

	wait for a work to finish executing the last queueing instance
1이면 flush 해야하고 0이면 idle상태
returns true if waited for the work to finish execution, false if it was already idle

struct delayed_work {
        struct work_struct work;
        struct timer_list timer;

        /* target workqueue and CPU ->timer uses to queue ->work */
        struct workqueue_struct *wq;
        int cpu;
};

DECLARE_DELAYED_WORK(name, void(*function)(struct work_struct *));
INIT_DELAYED_WORK(struct delayed_work *work, void(*function)(struct work_struct *));
bool schedule_delayed_work(struct delayed_work *dwork,
                                         unsigned long delay);

bool schedule_delayed_work_on(int cpu, struct delayed_work *dwork,
                                            unsigned long delay);

bool flush_delayed_work(struct delayed_work *dwork);
타이머 취소하고 즉시 실행하기 위해 큐에 바로 집어넣음

bool cancel_delayed_work(struct delayed_work *dwork)

INIT_WORK
queue_work
cancel_work_sync
flush_work
destroy_work
```

# 정리

## softirqs

- 인터럽트 컨텍스트
- 재진입가능
- sleep 불가능
- preempted / scheduled 불가능
- 쉽게 사용불가
- work가 sleep하지 않고 빠른 속도를 원하는 경우 사용

## Tasklet

- 인터럽트 컨텍스트
- 다른 cpu에서 같은 태스크릿 실행불가(Re-entrancy만족안함)
- sleep 불가
- 선점/스케쥴 불가
- 쉽게 사용가능
- 워크사용할 때 sleep 안하는 경우 이용함

## Workqueues

- 프로세스 컨텍스트
- 재진입가능
- sleep 가능
- 선점/스케쥴 가능
- sleep이 필요한 경우 사용

kworker

kworker/%u:%d%s (cpu, id, priority)

CPU Bound  : It is named as kworker/<corenumber>:<id>
CPU Unbound: It is named as kworker/u<poolnumber>:<id>

```c
struct workqueue_struct *alloc_workqueue(const char *fmt,
                                         unsigned int flags,
                                         int max_active, ...);

void destroy_workqueue(struct workqueue_struct *wq)

WQ_UNBOUND : 특정 cpu에 bind 되지않고 어느 프로세서에서는 사용가능
WQ_HIGHPRI : high priority worker-pool에다 큐잉하는것
WQ_SYSFS : 워크큐를 sysfs에 표시 sys/devices/virtual/workqueue
WQ_FREEZABLE : system suspend operations(전원관리나 시스템 이미지 생성시 사용)
WQ_MEM_RECLAIM : 메모리 부족시 구조자 스레드가 실행하다 말은 work item마저 
다 실행하게끔 깨워서 문제해결. 메모리 부족하면 work_item 실행이 불가능해짐..
WQ_CPU_INTENSIVE : cpu사용시간 길때 사용
같은 워커풀에 있는 work item이 실행되는 것을 방해하지않음
kworker/2:1 kworker/2:2 두개 있다 치면 한 work item이
두 워커 스레드를 다 사용하는 경우가 생길수 있음

WQ_MAX_UNBOUND_PER_CPU : cpu와 associated가능한 unbound workqueues수
WQ_UNBOUND_MAX_ACTIVE : unbound 워크큐의 총 갯수
[18142.095507] test_tasklet_init: Max unbounded per cpu:4
[18142.095521] test_tasklet_init: Max unbounded active:512

워크큐 두개 다르게 해놓고 따로따로 work item 넣어서 sleep하면
번갈아가면서 실행되는 걸 볼 수 있음
하지만 같은 워크큐라면 하나하나씩 실행됨

static inline struct delayed_work *to_delayed_work(struct work_struct *work)
{
        return container_of(work, struct delayed_work, work);
}
struct delayed_work *my_delayed_work = to_delayed_work(work);

워크함수에다가
queue_delayed_work(my_queue, &deferred_work1.work, msecs_to_jiffies(1000));
이렇게 해두면 periodic하게 사용가능함

큐에 있는 모든 work item이 끝날때 까지 sleep
void flush_workqueue(struct workqueue_struct *wq);

지정된 시간에 최대 하나의 작업 항목을 대기열에 실행합니다.
max_active가 1개임
#define alloc_ordered_workqueue(fmt, flags, args...)
```